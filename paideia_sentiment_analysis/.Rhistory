classe_specifica <- 'positive'
dataframe_classe <- dataframe_tf_full[dataframe_tf_full$classe==classe_specifica,]
colnames(dataframe_classe)
nrow(dataframe_classe)
dataframe_classe_ordinato <- head(dataframe_classe[order(-dataframe_classe$tf),],20)
dataframe_classe_ordinato
ggplot(data=dataframe_classe_ordinato) +
geom_bar(mapping=aes(x=reorder(tokens,-Freq) , y=Freq), stat='identity')
sw
colnames(dataframe_tf)
colnames(dataframe_tf_pos)
dataframe_tf_neg$tokens
# visualizzare parole per frequenza data una classe
classe_specifica <- 'positive'
dataframe_classe <- dataframe_tf_full[dataframe_tf_full$classe==classe_specifica,]
dataframe_classe
colnames(dataframe_classe)
nrow(dataframe_classe)
dataframe_classe_ordinato <- head(dataframe_classe[order(-dataframe_classe$tf),],20)
dataframe_classe_ordinato
get_frequencies <- function(polarity){
testi_classe <- my_data[my_data$Style==polarity,]$Text
tokens_classe <- unlist(tokenize_words(testi_classe))
tokens_classe <- tokens_classe[!tokens_classe %in% sw]
dataframe_tf <- as.data.frame(
table(
factor(
tokens_classe, levels = unique(tokens_full)
)
#tokens_classe
)
)
dataframe_tf['tf'] <- dataframe_tf$Freq/length(tokens_classe)
dataframe_tf['classe'] <- c(polarity)
dataframe_tf <- rename(dataframe_tf, 'tokens'=tokens_classe)
return(dataframe_tf)
}
dataframe_tf_pos <- get_frequencies("positive")
dataframe_tf_neg <- get_frequencies("negative")
dataframe_tf_full <- bind_rows(
dataframe_tf_pos,
dataframe_tf_neg,
.id = "column_label")
tokens_full <- tokens_full[!tokens_full %in% sw]
get_frequencies <- function(polarity){
testi_classe <- my_data[my_data$Style==polarity,]$Text
tokens_classe <- unlist(tokenize_words(testi_classe))
tokens_classe <- tokens_classe[!tokens_classe %in% sw]
dataframe_tf <- as.data.frame(
table(
factor(
tokens_classe, levels = unique(tokens_full)
)
#tokens_classe
)
)
dataframe_tf['tf'] <- dataframe_tf$Freq/length(tokens_classe)
dataframe_tf['classe'] <- c(polarity)
print(colnames(dataframe_tf))
dataframe_tf <- rename(dataframe_tf, 'tokens'=tokens_classe)
return(dataframe_tf)
}
dataframe_tf_pos <- get_frequencies("positive")
get_frequencies <- function(polarity){
testi_classe <- my_data[my_data$Style==polarity,]$Text
tokens_classe <- unlist(tokenize_words(testi_classe))
tokens_classe <- tokens_classe[!tokens_classe %in% sw]
dataframe_tf <- as.data.frame(
table(
#factor ci serve ad avere anche i token che compaiono con occorrenza = 0 in una data classe
factor(
tokens_classe, levels = unique(tokens_full)
)
#tokens_classe
)
)
dataframe_tf['tf'] <- dataframe_tf$Freq/length(tokens_classe)
dataframe_tf['classe'] <- c(polarity)
dataframe_tf <- rename(dataframe_tf, 'tokens'=Var1)
return(dataframe_tf)
}
dataframe_tf_pos <- get_frequencies("positive")
dataframe_tf_neg <- get_frequencies("negative")
dataframe_tf_full <- bind_rows(
dataframe_tf_pos,
dataframe_tf_neg,
.id = "column_label")
head(dataframe_tf_full)
parola <- 'salvini'
dataframe_parola <- dataframe_tf_full[dataframe_tf_full$tokens==parola,]
dataframe_parola
ggplot(data=dataframe_parola) +
geom_bar(mapping=aes(x=classe, y=tf), stat='identity')
parola <- 'pessimo'
dataframe_parola <- dataframe_tf_full[dataframe_tf_full$tokens==parola,]
dataframe_parola
ggplot(data=dataframe_parola) +
geom_bar(mapping=aes(x=classe, y=tf), stat='identity')
# visualizzare parole per frequenza data una classe
classe_specifica <- 'positive'
dataframe_classe <- dataframe_tf_full[dataframe_tf_full$classe==classe_specifica,]
dataframe_classe
colnames(dataframe_classe)
nrow(dataframe_classe)
dataframe_classe_ordinato <- head(dataframe_classe[order(-dataframe_classe$tf),],20)
dataframe_classe_ordinato
ggplot(data=dataframe_classe_ordinato) +
geom_bar(mapping=aes(x=reorder(tokens,-Freq) , y=Freq), stat='identity')
dataframe_classe_ordinato <- head(dataframe_classe[order(-dataframe_classe$tf),],10)
dataframe_classe_ordinato
ggplot(data=dataframe_classe_ordinato) +
geom_bar(mapping=aes(x=reorder(tokens,-Freq) , y=Freq), stat='identity')
parola <- 'salvini'
dataframe_parola <- dataframe_tf_full[dataframe_tf_full$tokens==parola,]
dataframe_parola
ggplot(data=dataframe_parola) +
geom_bar(mapping=aes(x=classe, y=tf), stat='identity')
# visualizzare parole per frequenza data una classe
classe_specifica <- 'positive'
dataframe_classe <- dataframe_tf_full[dataframe_tf_full$classe==classe_specifica,]
dataframe_classe
colnames(dataframe_classe)
nrow(dataframe_classe)
dataframe_classe_ordinato <- head(dataframe_classe[order(-dataframe_classe$tf),],10)
dataframe_classe_ordinato
ggplot(data=dataframe_classe_ordinato) +
geom_bar(mapping=aes(x=reorder(tokens,-Freq) , y=Freq), stat='identity')
table_tokens
# calcoliamo le idf
table_tokens <- table(tokens_full)
table_tokens
tokens_full
frasi_tokenizzate <- lapply(frasi_tokenizzate, unique)
# calcoliamo le idf
frasi_tokenizzate <- tokenize_words(testi)
frasi_tokenizzate <- lapply(frasi_tokenizzate, unique)
frasi_tokenizzate
token_per_frasi <- unlist(frasi_tokenizzate)
table_tokens <- table(token_per_frasi)
dataframe_df_full <- as.data.frame(table_tokens)
dataframe_df_full['idf'] <- log(
length(testi_full)/
dataframe_df_full['Freq']
)
dataframe_df_full['idf'] <- log(
length(testi)/
dataframe_df_full['Freq']
)
dataframe_df_full <- dataframe_df_full[dataframe_df_full$Freq >= 100,]
dataframe_df_full <- rename(dataframe_df_full, tokens=tokens_full)
dataframe_df_full
dataframe_df_full <- rename(dataframe_df_full, tokens=token_per_frasi)
head(dataframe_df_full)
# uniamo tf e idf
dataframe_tf_idf <- merge(dataframe_df_full, dataframe_tf_full, by='tokens')
colnames(dataframe_tf_idf)
dataframe_tf_idf['tfidf'] <- dataframe_tf_idf$tf*dataframe_tf_idf$idf
parola <- 'ottimo'
dataframe_parola <- dataframe_tf_idf[dataframe_tf_idf['tokens']==parola,]
dataframe_parola
dataframe_tf_idf
parola <- 'salvini'
dataframe_parola <- dataframe_tf_idf[dataframe_tf_idf['tokens']==parola,]
dataframe_parola
ggplot(data=dataframe_parola) +
geom_bar(mapping=aes(x=classe, y=tfidf), stat='identity')
dataframe_parola <- dataframe_tf_idf[dataframe_tf_idf['tokens']==parola,]
dataframe_parola
ggplot(data=dataframe_parola) +
geom_bar(mapping=aes(x=classe, y=tfidf), stat='identity')
#visualizzare parole per tfidf data una classe
classe <- 'positive'
dataframe_classe <- dataframe_tf_idf[dataframe_tf_idf['classe']==classe,]
dataframe_classe_ordinato <- dataframe_classe[order(-dataframe_classe$tfidf),]
head(dataframe_classe_ordinato, 20)
#visualizzare parole per tfidf data una classe
classe <- 'negative'
dataframe_classe <- dataframe_tf_idf[dataframe_tf_idf['classe']==classe,]
dataframe_classe_ordinato <- dataframe_classe[order(-dataframe_classe$tfidf),]
head(dataframe_classe_ordinato, 20)
dataframe_classe <- dataframe_tf_idf[dataframe_tf_idf['classe']==classe,]
dataframe_classe_ordinato <- dataframe_classe[order(dataframe_classe$tfidf),]
head(dataframe_classe_ordinato, 20)
dataframe_tf_neg <- get_frequencies("not applicable")
dataframe_tf_pos <- get_frequencies("positive")
dataframe_tf_neg <- get_frequencies("negative")
dataframe_tf_na <- get_frequencies("not applicable")
dataframe_tf_full <- bind_rows(
dataframe_tf_pos,
dataframe_tf_neg,
.id = "column_label")
head(dataframe_tf_full)
parola <- 'salvini'
dataframe_parola <- dataframe_tf_full[dataframe_tf_full$tokens==parola,]
dataframe_parola
ggplot(data=dataframe_parola) +
geom_bar(mapping=aes(x=classe, y=tf), stat='identity')
get_frequencies <- function(polarity){
testi_classe <- my_data[my_data$Style==polarity,]$Text
tokens_classe <- unlist(tokenize_words(testi_classe))
tokens_classe <- tokens_classe[!tokens_classe %in% sw]
dataframe_tf <- as.data.frame(
table(
#factor ci serve ad avere anche i token che compaiono con occorrenza = 0 in una data classe
factor(
tokens_classe, levels = unique(tokens_full)
)
#tokens_classe
)
)
dataframe_tf['tf'] <- dataframe_tf$Freq/length(tokens_classe)
dataframe_tf['classe'] <- c(polarity)
dataframe_tf <- rename(dataframe_tf, 'tokens'=Var1)
return(dataframe_tf)
}
dataframe_tf_pos <- get_frequencies("positive")
dataframe_tf_neg <- get_frequencies("negative")
dataframe_tf_na <- get_frequencies("not applicable")
dataframe_tf_full <- bind_rows(
dataframe_tf_pos,
dataframe_tf_neg,
dataframe_tf_na,
.id = "column_label")
head(dataframe_tf_full)
parola <- 'salvini'
dataframe_parola <- dataframe_tf_full[dataframe_tf_full$tokens==parola,]
dataframe_parola
ggplot(data=dataframe_parola) +
geom_bar(mapping=aes(x=classe, y=tf), stat='identity')
# visualizzare parole per frequenza data una classe
classe_specifica <- 'positive'
dataframe_classe <- dataframe_tf_full[dataframe_tf_full$classe==classe_specifica,]
dataframe_classe
colnames(dataframe_classe)
nrow(dataframe_classe)
dataframe_classe_ordinato <- head(dataframe_classe[order(-dataframe_classe$tf),],10)
dataframe_classe_ordinato
ggplot(data=dataframe_classe_ordinato) +
geom_bar(mapping=aes(x=reorder(tokens,-Freq) , y=Freq), stat='identity')
frasi_tokenizzate <- tokenize_words(testi)
frasi_tokenizzate <- lapply(frasi_tokenizzate, unique)
token_per_frasi <- unlist(frasi_tokenizzate)
table_tokens <- table(token_per_frasi)
dataframe_df_full <- as.data.frame(table_tokens)
dataframe_df_full['idf'] <- log(
length(testi)/
dataframe_df_full['Freq']
)
dataframe_df_full <- rename(dataframe_df_full, tokens=token_per_frasi)
head(dataframe_df_full)
# uniamo tf e idf
dataframe_tf_idf <- merge(dataframe_df_full, dataframe_tf_full, by='tokens')
colnames(dataframe_tf_idf)
dataframe_tf_idf['tfidf'] <- dataframe_tf_idf$tf*dataframe_tf_idf$idf
parola <- 'salvini'
dataframe_parola <- dataframe_tf_idf[dataframe_tf_idf['tokens']==parola,]
dataframe_parola
ggplot(data=dataframe_parola) +
geom_bar(mapping=aes(x=classe, y=tfidf), stat='identity')
parola <- 'pessimo'
dataframe_parola <- dataframe_tf_idf[dataframe_tf_idf['tokens']==parola,]
dataframe_parola
ggplot(data=dataframe_parola) +
geom_bar(mapping=aes(x=classe, y=tfidf), stat='identity')
#visualizzare parole per tfidf data una classe
classe <- 'negative'
dataframe_classe <- dataframe_tf_idf[dataframe_tf_idf['classe']==classe,]
dataframe_classe_ordinato <- dataframe_classe[order(-dataframe_classe$tfidf),]
head(dataframe_classe_ordinato, 20)
ggplot(data=head(dataframe_classe_ordinato,10)) +
geom_bar(mapping=aes(x=reorder(tokens,tfidf) , y=tfidf), stat='identity')
#visualizzare parole per tfidf data una classe
classe <- 'not applicable'
dataframe_classe <- dataframe_tf_idf[dataframe_tf_idf['classe']==classe,]
dataframe_classe_ordinato <- dataframe_classe[order(-dataframe_classe$tfidf),]
head(dataframe_classe_ordinato, 20)
ggplot(data=head(dataframe_classe_ordinato,10)) +
geom_bar(mapping=aes(x=reorder(tokens,tfidf) , y=tfidf), stat='identity')
my_data <- read_excel("../materiali/dataset.xlsx")
my_data <- data.frame(my_data)
my_data$Style[my_data$Style == "positivr"] = "positive"
sw <- stopwords("it")
testi <- my_data$Text
#tokenizzazione
tokens_full <- tokenize_words(testi)
tokens_full <- unlist(tokens_full)
tokens_full <- tokens_full[!tokens_full %in% sw]
#importare lessico esterno
nrc_table <- as.data.frame(
fread('./NRC-VAD-Lexicon-Aug2018Release/OneFilePerLanguage/Italian-it-NRC-VAD-Lexicon.txt'
)
)
library(tidyverse)
library(ggplot2)
library(tokenizers)
library(wordcloud)
library(RColorBrewer)
library(SnowballC)
library(udpipe)
library(stopwords)
library(R.utils)
library(tm)
require(data.table)
library(readxl)
#importare lessico esterno
nrc_table <- as.data.frame(
fread('./NRC-VAD-Lexicon-Aug2018Release/OneFilePerLanguage/Italian-it-NRC-VAD-Lexicon.txt'
)
)
head(nrc_table)
nrc_table[nrc_table["Italian-it"] == 'abaco',]$Valence[1]
nrc_table[nrc_table["Italian-it"] == 'abaco',]$Valence[1]
nrc_table[nrc_table["Italian-it"] == 'perfetto',]$Valence[1]
nrc_table[nrc_table["Italian-it"] == 'pessimo',]$Valence[1]
nrc_table[nrc_table["Italian-it"] == 'fiducioso',]$Valence[1]
frase <- c("Sono molto fiducioso per il futuro")
tokens_frase <- tokenize_words(frase)
tokens_frase <- unlist(tokens_frase)
tokens_frase <- tokens_frase[!tokens_frase %in% sw]
nrc_table[is.element(nrc_table$`Italian-it`, tokens_frase),]
mean(nrc_table[is.element(nrc_table$`Italian-it`, tokens_frase),]$Valence)
calcolare_sentiment_nrc <- function(frase_input){
tokens <- unlist(tokenize_words(frase_input))
tokens_clean <- tokens[!tokens %in% sw]
return(mean(nrc_table[is.element(nrc_table$`Italian-it`, tokens_clean),]$Valence))
}
sentiment_values <- unlist(lapply(testi_full, calcolare_sentiment_nrc))
sentiment_values <- unlist(lapply(testi, calcolare_sentiment_nrc))
sentiment_values[is.na(sentiment_values)] <- 0
sentiment_values_dataframe <- data.frame(
testi_full, sentiment_values
)
sentiment_values_dataframe <- data.frame(
testi, sentiment_values
)
head(sentiment_values_dataframe)
sentiment_values_dataframe  <- sentiment_values_dataframe[
order(-sentiment_values_dataframe$sentiment_values)
,]
sentiment_values_dataframe$index <- seq(
from=1,
to=nrow(sentiment_values_dataframe),
by=1)
colnames(sentiment_values_dataframe)
head(sentiment_values_dataframe)
ggplot(sentiment_values_dataframe, aes(x=index, y=sentiment_values))+
geom_bar(stat='identity', aes(fill=sentiment_values))
sentiment_values_dataframe$polarity <- ifelse(
sentiment_values_dataframe$sentiment_values >= 0.7,
"positivo",
ifelse(sentiment_values_dataframe$sentiment_values <= 0.5,
"negativo",
"neutro")
)
ggplot(sentiment_values_dataframe, aes(x=index, y=sentiment_values))+
geom_bar(stat='identity', aes(fill=polarity))+
scale_fill_manual(name='polarity',
labels=c('positivo', 'negativo', 'neutro'),
values = c("positivo"="#00ba38",
"negativo"="#f8766d",
"neutro"="#929292")) +
coord_flip()
#correlazione tra questa sentiment e le review
sentiment_values_dataframe <- data.frame(
sentiment_values, stars
)
style <- my_data$Style
#correlazione tra la sentiment calcolata e le statistiche del dataset
sentiment_values_dataframe <- data.frame(
sentiment_values, style
)
ggplot(sentiment_values_dataframe, aes(x=stars, y=sentiment_values)) +
geom_point()
ggplot(sentiment_values_dataframe, aes(x=style, y=sentiment_values)) +
geom_point()
errori <- sentiment_values_dataframe[
sentiment_values_dataframe$style == 1 &
sentiment_values_dataframe$sentiment_values >= 0.25
,]
length(sentiment_values)
errori <- sentiment_values_dataframe[
sentiment_values_dataframe$style == 'negative' &
sentiment_values_dataframe$sentiment_values >= 0.25
,]
errori
testi[67]
token_per_frasi[67]
tokens_full[67]
#tokenizzazione
tokens_full <- tokenize_words(testi)
tokens_full <- tokens_full[!tokens_full %in% sw]
sentiment_values <- ifelse(
is.element(nrc_table$`Italian-it`, token_frase),
mean(nrc_table[is.element(nrc_table$`Italian-it`, tokens_frase),]$Valence),
0)
sentiment_values <- ifelse(
is.element(nrc_table$`Italian-it`, tokens_frase),
mean(nrc_table[is.element(nrc_table$`Italian-it`, tokens_frase),]$Valence),
0)
sentiment_values
sentiment_values <- ifelse(
tokens_frase %in% nrc_table$`Italian-it`,
mean(nrc_table[is.element(nrc_table$`Italian-it`, tokens_frase),]$Valence),
0)
sentiment_values
tokens_frase <- tokenize_words(frase)
tokens_frase <- unlist(tokens_frase)
tokens_frase <- tokens_frase[!tokens_frase %in% sw]
tokens_frase
frase <- c("Sono molto fiducioso per il futuro, anche se mi sento un po' preoccupato a causa degli ultimi avvenimenti")
tokens_frase <- tokenize_words(frase)
tokens_frase <- unlist(tokens_frase)
tokens_frase <- tokens_frase[!tokens_frase %in% sw]
tokens_frase
nrc_table[is.element(nrc_table$`Italian-it`, tokens_frase),]
sentiment_values <- ifelse(
tokens_frase %in% nrc_table$`Italian-it`,
mean(nrc_table[is.element(nrc_table$`Italian-it`, tokens_frase),]$Valence),
0)
sentiment_values
mean(sentiment_values)
sentiment_values <- ifelse(
tokens_frase %in% nrc_table$`Italian-it`,
nrc_table[is.element(nrc_table$`Italian-it`, tokens_frase),]$Valence,
0)
sentiment_values
mean(sentiment_values)
sentiment_values <- ifelse(
tokens_frase %in% nrc_table$`Italian-it`,
nrc_table[is.element(nrc_table$`Italian-it`, tokens_frase),]$Valence,
1/length(tokens_frase))
sentiment_values
mean(sentiment_values)
#ifelse: se il valore Ã¨ in nrc, usare il valore di valenza
#altrimenti dare un valore "neutro", ovvero 1/lunghezza in token della frase
sentiment_values <- ifelse(
tokens_frase %in% nrc_table$`Italian-it`,
nrc_table[is.element(nrc_table$`Italian-it`, tokens_frase),]$Valence,
1/length(tokens_frase))
mean(sentiment_values)
mean(nrc_table[is.element(nrc_table$`Italian-it`, tokens_frase),]$Valence)
sentiment_values
mean(sentiment_values)
mean(sentiment_values>=0.1)
mean(sentiment_values[sentiment_values>=0.1])
sentiment_values <- nrc_table[is.element(nrc_table$`Italian-it`, tokens_frase),]$Valence
sentiment_values
mena(sentiment_values)
mean(sentiment_values)
return(mean(sentiment_values)
}
sentiment_values <- unlist(lapply(testi, calcolare_sentiment_nrc))
sentiment_values[is.na(sentiment_values)] <- 0
sentiment_values_dataframe <- data.frame(
testi, sentiment_values
)
head(sentiment_values_dataframe)
sentiment_values_dataframe  <- sentiment_values_dataframe[
order(-sentiment_values_dataframe$sentiment_values)
,]
sentiment_values_dataframe$index <- seq(
from=1,
to=nrow(sentiment_values_dataframe),
by=1)
colnames(sentiment_values_dataframe)
head(sentiment_values_dataframe)
ggplot(sentiment_values_dataframe, aes(x=index, y=sentiment_values))+
geom_bar(stat='identity', aes(fill=sentiment_values))
# impostiamo dei limiti:
# negativo = minore di 0.5
# neutro = compreso tra 0.5 e 0.7
# positivo = maggiore di 0.7
sentiment_values_dataframe$polarity <- ifelse(
sentiment_values_dataframe$sentiment_values >= 0.7,
"positivo",
ifelse(sentiment_values_dataframe$sentiment_values <= 0.5,
"negativo",
"neutro")
)
ggplot(sentiment_values_dataframe, aes(x=index, y=sentiment_values))+
geom_bar(stat='identity', aes(fill=polarity))+
scale_fill_manual(name='polarity',
labels=c('positivo', 'negativo', 'neutro'),
values = c("positivo"="#00ba38",
"negativo"="#f8766d",
"neutro"="#929292")) +
coord_flip()
#correlazione tra la sentiment calcolata e le statistiche del dataset
sentiment_values_dataframe <- data.frame(
sentiment_values, style
)
ggplot(sentiment_values_dataframe, aes(x=style, y=sentiment_values)) +
geom_point()
# controlliamo quali testi presentano problematiche
errori <- sentiment_values_dataframe[
sentiment_values_dataframe$style == 'negative' &
sentiment_values_dataframe$sentiment_values >= 0.25
,]
errori
tokens_full[67]
calcolare_sentiment_nrc <- function(frase_input){
tokens <- unlist(tokenize_words(frase_input))
tokens_clean <- tokens[!tokens %in% sw]
sentiment_values <- nrc_table[is.element(nrc_table$`Italian-it`, tokens_clean),]$Valence
return(mean(sentiment_values))
}
errori <- sentiment_values_dataframe[
sentiment_values_dataframe$style == 'negative' &
sentiment_values_dataframe$sentiment_values >= 0.25
,]
errori
tokens_full[67]
