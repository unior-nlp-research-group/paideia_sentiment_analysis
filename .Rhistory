tokens_positive <- unlist(tokens_positive)
]
tokens_positive <- tokens_full[my_data$Style=="positive"]
tokens_positive[1]
tokens_positive <- unlist(tokens_positive)
set.seed(1234)
wordcloud(words = tokens_positive, freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=1000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(3.5,0.25))
tokens_full %in% sw
#tokenizzazione ed eliminazione stop word
tokens_full <- tokenize_words(testi)
tokens_full %in% sw
table(tokens_full %in% sw)
#tokenizzazione ed eliminazione stop word
tokens_full <- tokenize_words(testi)
tokens_positive <- tokens_positive[!tokens_positive %in% sw]
set.seed(1234)
tokens_full[1]
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=1000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(3.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=1000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=50, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=100, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=1000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=10000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 5,
max.words=500, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 5,
max.words=500, random.order=FALSE,
colors=brewer.pal(8, "Dark"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 5,
max.words=500, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 5,
max.words=500, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 100,
max.words=500, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.freq = 100,
max.words=500, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 100,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=TRUE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
library(wordcloud2)
install.packages("wordcloud2")
library(wordcloud2)
set.seed(1234)
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
library(wordcloud2)
wordcloud2(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud2(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud2(unique(tokens_positive),
#freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud2(unique(tokens_positive),
#freq = as.data.frame(table(tokens_positive))$Freq,
#min.freq = 5,
#max.words=500,
#random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud2(unique(tokens_positive),
#freq = as.data.frame(table(tokens_positive))$Freq,
#min.freq = 5,
#max.words=500,
#random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
#scale=c(2.5,0.25)
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25),
rot.per=90
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25),
rot.per=45
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(9, "BuGn"),
scale=c(2.5,0.25),
rot.per=45
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(9, "BuGn"),
scale=c(2.5,0.25),
rot.per=0
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(9, "Dark2"),
scale=c(2.5,0.25),
rot.per=0
)
?brewer.pal
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(9, "Dark2"),
scale=c(2.5,0.25)
)
?brewer.pal
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(9, "Pastel1"),
scale=c(2.5,0.25)
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(9, "Set1"),
scale=c(2.5,0.25)
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(3, "Set1"),
scale=c(2.5,0.25)
)
?brewer.pal
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Accent"),
scale=c(2.5,0.25)
)
?wordcloud
ggplot(my_data) +
geom_bar(aes(y=Style, fill=Style))
unique(my_data$Style)
table(my_data$Style)
ggplot(my_data) +
geom_bar(aes(y=Style, fill=Style))
freq_tokens <- data.frame(table(tokens_full))
freq_tokens <- data.frame(table(tokens_full))
freq_tokens <- data.frame(table(unlist(tokens_full)))
freq_tokens <- freq_tokens[order(-freq_tokens$Freq)]
freq_tokens <- freq_tokens[order(-freq_tokens$Freq),]
ggplot(freq_tokens) +
geom_bar(aes(y=Freq, fill=Freq))
colnames(freq_tokens)
ggplot(freq_tokens) +
geom_bar(aes(x=Var1, y=Freq))
ggplot(freq_tokens) +
geom_bar(aes(x=Var1, y=Freq), stat="identity")
ggplot(head(freq_tokens)) +
geom_bar(aes(x=Var1, y=Freq), stat="identity")
?geom_bar
?ggplot
ggplot(head(freq_tokens)) +
geom_bar(aes(x=Var1, y=Freq), stat="identity")
my_data$x <- rep(c(1:5), nrow(my_data)%/%5)
my_data$y <- rep(c(1:5), nrow(my_data)%/%5)
ggplot(my_data, aes(id))+
geom_raster(aes(fill=style_num))
library(tidyverse)
library(ggplot2)
library(tokenizers)
library(wordcloud2)
library(RColorBrewer)
library(SnowballC)
library(udpipe)
library(readxl)
library(stopwords)
library(R.utils)
library(tm)
library(data.table)
fake_news <- read_excel('./materiali/bufala-bufale.xlsx')
real_news <- read_excel('./materiali/notizia-vera-bufale.xlsx')
colnames(fake_news)
fake_news <- fake_news$Field2
real_news <- real_news$Field2
fake_news_tokens <- tokenize_words(fake_news)
real_news_tokens <- tokenize_words(real_news)
length(fake_news_tokens)
View(fake_news_tokens)
fake_news_tokens <- unlist(tokenize_words(fake_news))
real_news_tokens <- unlist(tokenize_words(real_news))
n_i <- length(fake_news_tokens)
n_j <- length(real_news_tokens)
parola <- "morto"
fake_news_tokens == parola
parola_i <- sum(fake_news_tokens == parola)
parola_j <- sum(real_news_tokens == parola)
parola_i
parola_j
n_i
parola <- "morto"
parola_i <- sum(fake_news_tokens == parola)
parola_j <- sum(real_news_tokens == parola)
parola_j
fake_news_tokens <- unlist(tokenize_words(fake_news))
real_news_tokens <- unlist(tokenize_words(real_news))
n_i <- length(fake_news_tokens)
n_j <- length(real_news_tokens)
parola <- "morto"
parola_i <- sum(fake_news_tokens == parola)
parola_j <- sum(real_news_tokens == parola)
parola_j
head(fake_news_tokens)
fake_news_tokens == parola
table(fake_news_tokens == parola)
sum(c(TRUE, TRUE))
parola_i <- sum(fake_news_tokens == "morto")
parola_i
class(fake_news_tokens)
parola_i <- sum(fake_news_tokens == "morto")
parola_j <- sum(real_news_tokens == parola)
parola_i
sum(fake_news_tokens == "morto")
sum(class(fake_news_tokens) == "character")
fake_news_tokens == "morto"
class(fake_news_tokens == "morto")
sum(is.na(fake_news_tokens == "morto"))
fake_news_tokens[is.na(fake_news_tokens == "morto"))]
fake_news_tokens[is.na(fake_news_tokens == "morto")]
table(fake_news_tokens )
table(fake_news_tokens)
table((fake_news_tokens == "morto"))
sum(is.na(fake_news_tokens))
is.na(fake_news)
sum(is.na(fake_news)9
sum(is.na(fake_news))
fake_news <- na.omit(fake_news)
fake_news <- na.omit(fake_news)
fake_news <- fake_news$Field2
fake_news
fake_news <- read_excel('./materiali/bufala-bufale.xlsx')
fake_news <- na.omit(fake_news)
fake_news <- fake_news$Field2
fake_news <- read_excel('./materiali/bufala-bufale.xlsx')
real_news <- read_excel('./materiali/notizia-vera-bufale.xlsx')
fake_news <- na.omit(fake_news)
real_news <- na.omit(real_news)
fake_news <- fake_news$Field2
real_news <- real_news$Field2
fake_news_tokens <- unlist(tokenize_words(fake_news))
real_news_tokens <- unlist(tokenize_words(real_news))
n_i <- length(fake_news_tokens)
n_j <- length(real_news_tokens)
parola <- "morto"
parola_i <- sum(fake_news_tokens == "morto")
parola_j <- sum(real_news_tokens == parola)
parola_i
alpha <- n_i + n_j
alpha <- c(fake_news_tokens, real_news_tokens)
length(alpha)
alpha <- c(fake_news_tokens, real_news_tokens)
n_alpha <- n_i + n_j
parola_alpha <- sum(alpha == parola)
parola_alpha
4/2
num1 <- log((parola_i + parola_alpha)/(n_i + n_alpha - (parola_i + parola_alpha)))
num2 <- log((parola_j + parola_alpha) / (n_j + n_alpha - (parola_j + parola_alpha)))
num <- num1 - num2
num
denom <- 1 / (parola_i  + parola_alpha) + 1 / (parola_j + parola_alpha)
denom
log_odd <- num / sqrt(denom)
log_odd
fake_news <- fake_news$Field1
real_news <- real_news$Field1
fake_news_tokens <- unlist(tokenize_words(fake_news))
real_news_tokens <- unlist(tokenize_words(real_news))
n_i <- length(fake_news_tokens)
n_j <- length(real_news_tokens)
parola <- "morto"
parola_i <- sum(fake_news_tokens == parola)
parola_j <- sum(real_news_tokens == parola)
alpha <- c(fake_news_tokens, real_news_tokens)
n_alpha <- n_i + n_j
parola_alpha <- sum(alpha == parola)
num1 <- log((parola_i + parola_alpha)/(n_i + n_alpha - (parola_i + parola_alpha)))
num2 <- log((parola_j + parola_alpha) / (n_j + n_alpha - (parola_j + parola_alpha)))
num <- num1 - num2
denom <- 1 / (parola_i  + parola_alpha) + 1 / (parola_j + parola_alpha)
log_odd <- num / sqrt(denom)
log_odd
francesco_totti <- function(parola){
parola_i <- sum(fake_news_tokens == parola)
parola_j <- sum(real_news_tokens == parola)
alpha <- c(fake_news_tokens, real_news_tokens)
n_alpha <- n_i + n_j
parola_alpha <- sum(alpha == parola)
num1 <- log((parola_i + parola_alpha)/(n_i + n_alpha - (parola_i + parola_alpha)))
num2 <- log((parola_j + parola_alpha) / (n_j + n_alpha - (parola_j + parola_alpha)))
num <- num1 - num2
denom <- 1 / (parola_i  + parola_alpha) + 1 / (parola_j + parola_alpha)
log_odd <- num / sqrt(denom)
return(log_odd)
}
francesco_totti("totti")
fake_news <- na.omit(fake_news)
real_news <- na.omit(real_news)
fake_news <- fake_news$Field2
real_news <- real_news$Field2
fake_news_tokens <- unlist(tokenize_words(lapply(fake_news, tolower))
real_news_tokens <- unlist(tokenize_words(lapply(real_news, tolower))
n_i <- length(fake_news_tokens)
n_j <- length(real_news_tokens)
fake_news <- read_excel('./materiali/bufala-bufale.xlsx')
real_news <- read_excel('./materiali/notizia-vera-bufale.xlsx')
fake_news <- na.omit(fake_news)
real_news <- na.omit(real_news)
fake_news <- fake_news$Field2
real_news <- real_news$Field2
fake_news_tokens <- unlist(tokenize_words(lapply(fake_news, tolower))
real_news_tokens <- unlist(tokenize_words(lapply(real_news, tolower))
n_i <- length(fake_news_tokens)
n_j <- length(real_news_tokens)
francesco_totti <- function(parola){
parola_i <- sum(fake_news_tokens == parola)
parola_j <- sum(real_news_tokens == parola)
alpha <- c(fake_news_tokens, real_news_tokens)
n_alpha <- n_i + n_j
parola_alpha <- sum(alpha == parola)
num1 <- log((parola_i + parola_alpha)/(n_i + n_alpha - (parola_i + parola_alpha)))
num2 <- log((parola_j + parola_alpha) / (n_j + n_alpha - (parola_j + parola_alpha)))
num <- num1 - num2
denom <- 1 / (parola_i  + parola_alpha) + 1 / (parola_j + parola_alpha)
log_odd <- num / sqrt(denom)
return(log_odd)
}
francesco_totti("berlusconi")
francesco_totti("totti")
francesco_totti("morti")
francesco_totti("morto")
fake_news_tokens <- unlist(tokenize_words(lapply(fake_news, tolower))
fake_news_tokens <- unlist(tokenize_words(lapply(fake_news, tolower)))
real_news_tokens <- unlist(tokenize_words(lapply(real_news, tolower)))
n_i <- length(fake_news_tokens)
n_j <- length(real_news_tokens)
alpha <- c(fake_news_tokens, real_news_tokens)
n_alpha <- n_i + n_j
francesco_totti <- function(parola){
parola_i <- sum(fake_news_tokens == parola)
parola_j <- sum(real_news_tokens == parola)
parola_alpha <- sum(alpha == parola)
num1 <- log((parola_i + parola_alpha)/(n_i + n_alpha - (parola_i + parola_alpha)))
num2 <- log((parola_j + parola_alpha) / (n_j + n_alpha - (parola_j + parola_alpha)))
num <- num1 - num2
denom <- 1 / (parola_i  + parola_alpha) + 1 / (parola_j + parola_alpha)
log_odd <- num / sqrt(denom)
return(log_odd)
}
alpha
tokens <- unique(alpha)
tokens_full <- unique(alpha)
log_odds_full <- lapply(tokens_full, francesco_totti)
df_logodds <- data.frame(
"token" = tokens_full,
"log_odds" = log_odds_full
)
head(df_logodds)
length(log_odds_full)
length(tokens_full)
nrow(df_logodds)
class(log_odds_full)
df_logodds <- data.frame(
"token" = tokens_full,
"log_odds" = unlist(log_odds_full)
)
head(df_logodds)
df_logodds <- data.frame(
"token" = tokens_full,
"log_odds" = unlist(log_odds_full)
)
df_logodds <- df_logodds[order(-log_odds)]
df_logodds <- df_logodds[order(-df_logodds$log_odds),]
df_logodds
head(df_logodds, 20)
df_logodds <- df_logodds[order(df_logodds$log_odds),]
head(df_logodds, 20)
df_logodds <- df_logodds[order(-df_logodds$log_odds),]
head(df_logodds, 20)
df_logodds <- df_logodds[order(-df_logodds$log_odds),]
tail(df_logodds, 20)
knitr::opts_chunk$set(echo = TRUE)
hist(x)
