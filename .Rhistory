style <- data_annotato$Style
data_annotato$id <- seq(from=1, to=nrow(data_annotato), by=1)
table(style)
# utilizzo dei lessici per la sentiment
#link nrc
# http://saifmohammad.com/WebPages/AccessResource.htm
#link sentix
# http://valeriobasile.github.io/twita/downloads.html
#importare lessico esterno
lessico <- as.data.frame(
fread('./materiali/sentix'
)
)
head(lessico)
#**andiamo a vedere i valori di una parola esemplificativa**
parola <- "non"
mean(lessico[lessico$V1 == parola,]$V4)
#calcoliamo il valore per una frase
frase <- c("Sono molto fiducioso per il futuro, anche se mi sento un po' preoccupato a causa degli ultimi avvenimenti")
tokens_frase <- tokenize_words(frase)
tokens_frase <- unlist(tokens_frase)
tokens_frase <- tokens_frase[!tokens_frase %in% sw]
polarity <- lessico[is.element(lessico$V1, tokens_frase),]$V4
tokens_interest <- lessico[is.element(lessico$V1, tokens_frase),]$V1
df <- data.frame(
polarity,
"tokens" = tokens_interest
)
head(df)
ggplot(df)+
geom_bar(aes(x=tokens, y = polarity), stat="summary", fun="mean")
sentiment_values <- lessico[is.element(lessico$V1, tokens_frase),]$V4
sentiment_values
round(mean(sentiment_values),3)
#**scriviamo una funzione per calcolare il valore di valenza data una frase**
calcolare_sentiment <- function(frase_input){
tokens <- unlist(tokenize_words(frase_input))
tokens_clean <- tokens[!tokens %in% sw]
sentiment_values <- lessico[is.element(lessico$V1, tokens_clean),]$V4
return(mean(sentiment_values))
}
sentiment_values <- unlist(
lapply(
testi_lemmatizzati, calcolare_sentiment))
hist(sentiment_values)
#quanti NA ci sono?
sentiment_values[is.na(sentiment_values)] <- 0
density(sentiment_values)
testi <- data_annotato$Text
sentiment_values_dataframe <- data.frame(
testi, sentiment_values
)
head(sentiment_values_dataframe)
sentiment_values_dataframe  <- sentiment_values_dataframe[
order(-sentiment_values_dataframe$sentiment_values)
,]
head(sentiment_values_dataframe)
sentiment_values_dataframe$index <- seq(
from=1,
to=nrow(sentiment_values_dataframe),
by=1)
colnames(sentiment_values_dataframe)
head(sentiment_values_dataframe)
# impostiamo dei limiti (threshold):
# negativo  <0.2
# neutro  >=0.4
# positivo  > 0.4
sentiment_values_dataframe$polarity <- ifelse(
sentiment_values_dataframe$sentiment_values > 0.4,
"positivo",
ifelse(sentiment_values_dataframe$sentiment_values < 0.2,
"negativo",
"neutro")
)
head(sentiment_values_dataframe$polarity)
table(sentiment_values_dataframe$polarity)
table(style)
# addestramento di un classificatore naive bayes
# creare split
set.seed(12)
#creazione di un indice per il training
train_index <- sample(nrow(sentiment_values_dataframe), 3000)
train_index
test_index <- sentiment_values_dataframe$index[
!sentiment_values_dataframe$index %in% train_index]
length(test_index)
#creazione di una dtm
corpus <- VCorpus(VectorSource(paste(testi_lemmatizzati)))
dtm <- DocumentTermMatrix(corpus)
dtm$dimnames$Docs
dtm_train <- dtm[dtm$dimnames$Docs %in% train_index,]
dtm_test <- dtm[dtm$dimnames$Docs %in% test_index,]
dtm_train
train_labels <- style[train_index]
test_labels <- style[-train_index]
table(train_labels)
library(e1071)
classifier <- naiveBayes(
as.matrix(dtm_train),
train_labels)
pred <- predict(classifier, as.matrix(dtm_test))
confusionMatrix(pred, as.factor(test_labels))
dtm_train <- removeSparseTerms(dtm_train, 0.5)
dtm_test <- removeSparseTerms(dtm_test, 0.5)
classifier <- naiveBayes(
as.matrix(dtm_train),
train_labels)
pred <- predict(classifier, as.matrix(dtm_test))
confusionMatrix(pred, as.factor(test_labels))
pos_ids <- data_annotato$id[data_annotato$Style == 'positive']
pos_texts <- VCorpus(VectorSource(testi_lemmatizzati[pos_ids]))
wordcloud(pos_texts, max.words=50, scale=c(4,0.5))
wordcloud(neg_texts, max.words=50, scale=c(4,0.5))
neg_ids <- data_annotato$id[data_annotato$Style == 'negative']
neg_texts <- VCorpus(VectorSource(testi_lemmatizzati[neg_ids]))
wordcloud(neg_texts, max.words=50, scale=c(4,0.5))
library(tidyverse)
library(ggplot2)
library(tokenizers)
library(wordcloud)
library(RColorBrewer)
library(SnowballC)
library(udpipe)
library(readxl)
library(stopwords)
library(R.utils)
library(tm)
library(data.table)
#ricarichiamo il nostro file di testo
my_data <- read_excel("./materiali/dataset.xlsx")
my_data <- data.frame(my_data)
my_data$id <- seq(1:nrow(my_data))
sw <- stopwords("it")
testi <- my_data$Text
style <- my_data$Style
#tokenizzazione ed eliminazione stop word
tokens_full <- tokenize_words(testi)
tokens_full <- tokens_full[!tokens_full %in% sw]
unique(style)
my_data$Style[my_data$Style == "positivr"] <- "positive"
my_data$Style[my_data$Style == "emphasising candidate's values"] <- "not applicable"
style <- my_data$Style
my_data$style_num <- ifelse(
my_data$Style=='positive',
1,
-1
)
my_data$style_num
ggplot(my_data)+
geom_bar(aes(y=Style, fill=Style))
ggplot(my_data, aes(id,0.5))+
geom_tile(aes(fill=style_num))
unique(my_data$Style)
ggplot(my_data, aes(id,0))+
geom_tile(aes(fill=style_num))
ggplot(my_data, aes(id,1))+
geom_tile(aes(fill=style_num))
ggplot(my_data, aes(id,-1))+
geom_tile(aes(fill=style_num))
ggplot(my_data, aes(id))+
geom_tile(aes(fill=style_num))
ggplot(my_data, aes(id, 1))+
geom_tile(aes(fill=style_num))
ggplot(my_data, aes(id, 1))+
geom_raster(aes(fill=style_num))
ggplot(my_data, aes(id, style_num))+
geom_raster(aes(fill=style_num))
ggplot(my_data, aes(id))+
geom_raster(aes(fill=style_num))
my_data <- expand.grid(x = 0:5, y = 0:5)
my_data
my_data <- read_excel("./materiali/dataset.xlsx")
my_data <- data.frame(my_data)
my_data$id <- seq(1:nrow(my_data))
my_data$Style[my_data$Style == "positivr"] <- "positive"
my_data$Style[my_data$Style == "emphasising candidate's values"] <- "not applicable"
my_data$Style <- ifelse(is.na(my_data$Style),
"not applicable",
my_data$Style)
style <- my_data$Style
length(my_data)
nrow(my_data)
rep(c(1:5), 10)
rep(c(1:5), nrow(my_data)%/%5)
library(tidyverse)
library(ggplot2)
library(tokenizers)
library(wordcloud)
library(RColorBrewer)
library(SnowballC)
library(udpipe)
library(readxl)
library(stopwords)
library(R.utils)
library(tm)
library(data.table)
?read_csv
?read.csv
#ricarichiamo il nostro file di testo
my_data <- read.csv("./materiali/dataset_fixed.csv")
my_data <- data.frame(my_data)
head(my_data)
head(my_data[,:2])
head(my_data[,1:2])
head(my_data[,1:4])
head(my_data[,1:3])
head(my_data[,1:2])
colnames(my_data)
testi <- my_data$Text
#tokenizzazione ed eliminazione stop word
tokens_full <- tokenize_words(testi)
tokens_full <- tokens_full[!tokens_full %in% sw]
style <- my_data$Style
testi_positive <- my_data[my_data$Style=="positive",]$Text
tokens_positive <- unlist(tokenize_words(testi_positive))
length(tokens_full)
# wordcloud
my_data[my_data$Style=="positive",]
# wordcloud
my_data$Style=="positive"
class(tokens_full)
tokens_positive <- tokens_full[my_data$Style=="positive"]
tokens_positive <- tokens_full[my_data$Style=="positive",]
tokens_positive <- tokens_full[my_data$Style=="positive"]
tokens_positive <- unlist(tokens_positive)
]
tokens_positive <- tokens_full[my_data$Style=="positive"]
tokens_positive[1]
tokens_positive <- unlist(tokens_positive)
set.seed(1234)
wordcloud(words = tokens_positive, freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=1000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(3.5,0.25))
tokens_full %in% sw
#tokenizzazione ed eliminazione stop word
tokens_full <- tokenize_words(testi)
tokens_full %in% sw
table(tokens_full %in% sw)
#tokenizzazione ed eliminazione stop word
tokens_full <- tokenize_words(testi)
tokens_positive <- tokens_positive[!tokens_positive %in% sw]
set.seed(1234)
tokens_full[1]
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=1000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(3.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=1000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=50, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=100, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=1000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 50,
max.words=10000, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 5,
max.words=500, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 5,
max.words=500, random.order=FALSE,
colors=brewer.pal(8, "Dark"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 5,
max.words=500, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(5.5,0.25))
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq, min.freq = 5,
max.words=500, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 100,
max.words=500, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.freq = 100,
max.words=500, random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 100,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=TRUE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
library(wordcloud2)
install.packages("wordcloud2")
library(wordcloud2)
set.seed(1234)
wordcloud(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
library(wordcloud2)
wordcloud2(words = tokens_positive,
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud2(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud2(unique(tokens_positive),
#freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud2(unique(tokens_positive),
#freq = as.data.frame(table(tokens_positive))$Freq,
#min.freq = 5,
#max.words=500,
#random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud2(unique(tokens_positive),
#freq = as.data.frame(table(tokens_positive))$Freq,
#min.freq = 5,
#max.words=500,
#random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
#scale=c(2.5,0.25)
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25)
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25),
rot.per=90
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"),
scale=c(2.5,0.25),
rot.per=45
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(9, "BuGn"),
scale=c(2.5,0.25),
rot.per=45
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(9, "BuGn"),
scale=c(2.5,0.25),
rot.per=0
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(9, "Dark2"),
scale=c(2.5,0.25),
rot.per=0
)
?brewer.pal
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(9, "Dark2"),
scale=c(2.5,0.25)
)
?brewer.pal
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(9, "Pastel1"),
scale=c(2.5,0.25)
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(9, "Set1"),
scale=c(2.5,0.25)
)
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(3, "Set1"),
scale=c(2.5,0.25)
)
?brewer.pal
wordcloud(unique(tokens_positive),
freq = as.data.frame(table(tokens_positive))$Freq,
min.freq = 5,
max.words=500,
random.order=FALSE,
colors=brewer.pal(8, "Accent"),
scale=c(2.5,0.25)
)
?wordcloud
ggplot(my_data) +
geom_bar(aes(y=Style, fill=Style))
unique(my_data$Style)
table(my_data$Style)
ggplot(my_data) +
geom_bar(aes(y=Style, fill=Style))
freq_tokens <- data.frame(table(tokens_full))
freq_tokens <- data.frame(table(tokens_full))
freq_tokens <- data.frame(table(unlist(tokens_full)))
freq_tokens <- freq_tokens[order(-freq_tokens$Freq)]
freq_tokens <- freq_tokens[order(-freq_tokens$Freq),]
ggplot(freq_tokens) +
geom_bar(aes(y=Freq, fill=Freq))
colnames(freq_tokens)
ggplot(freq_tokens) +
geom_bar(aes(x=Var1, y=Freq))
ggplot(freq_tokens) +
geom_bar(aes(x=Var1, y=Freq), stat="identity")
ggplot(head(freq_tokens)) +
geom_bar(aes(x=Var1, y=Freq), stat="identity")
?geom_bar
?ggplot
ggplot(head(freq_tokens)) +
geom_bar(aes(x=Var1, y=Freq), stat="identity")
my_data$x <- rep(c(1:5), nrow(my_data)%/%5)
my_data$y <- rep(c(1:5), nrow(my_data)%/%5)
ggplot(my_data, aes(id))+
geom_raster(aes(fill=style_num))
