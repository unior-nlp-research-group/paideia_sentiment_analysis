library(tidyverse)
library(ggplot2)
library(tokenizers)
library(wordcloud)
library(RColorBrewer)
library(SnowballC)
library(udpipe)
library(stopwords)
library(R.utils)
library(tm)
#ricarichiamo il nostro file di testo
my_data <- read_excel("../materiali/dataset.xlsx")
my_data <- data.frame(my_data)
install.packages("RtextTools")
install.packages("RTextTools")
install.packages("e1071")
install.packages("caret")
install.packages("caret")
index >- sample(1:nrow(my_data), size = .9 * nrow(my_data))
index <- sample(1:nrow(my_data), size = .9 * nrow(my_data))
#ricarichiamo il nostro file di testo
my_data <- read_excel("../materiali/dataset.xlsx")
my_data <- data.frame(my_data)
index <- sample(1:nrow(my_data), size = .9 * nrow(my_data))
#ricarichiamo il nostro file di testo
my_data <- read_excel("../materiali/dataset.xlsx")
library(caret)
install.packages("caret")
library(caret)
#importiamo le librerie che useremo in questa giornata
library(tidyverse)
library(ggplot2)
library(tokenizers)
library(wordcloud)
library(RColorBrewer)
library(SnowballC)
library(udpipe)
library(stopwords)
library(R.utils)
library(tm)
library(RTextTools)
library(e1071)
#ricarichiamo il nostro file di testo
my_data <- read_excel("../materiali/dataset.xlsx")
library(readxl)
#ricarichiamo il nostro file di testo
my_data <- read_excel("../materiali/dataset.xlsx")
my_data <- data.frame(my_data)
index <- sample(1:nrow(my_data), size = .9 * nrow(my_data))
index
train_split <- df[index,]
test_split <- df[-index,]
test_split <- df[-index, ]
train_split <- my_data[index, ]
test_split <- my_data[-index, ]
head(train_split)
head(train_split[,2])
m_train <- create_matrix(train_split[,2],
language='italian',
removeStopwords = FALSE,
removeNumbers = TRUE,
stemWords = FALSE)
m_train
matTrain <- as.matrix(mTrain)
matTrain <- as.matrix(m_train)
matTrain
print(matTrain)
print(m_train)
m_train <- create_matrix(train_split[,2],
language='italian',
removeStopwords = FALSE,
removeNumbers = TRUE,
stemWords = FALSE)
m_train <- create_matrix(train_split[,2],
language='english',
removeStopwords = FALSE,
removeNumbers = TRUE,
stemWords = FALSE)
head(train_split)
head(train_split$Text)
m_train <- create_matrix(train_split$Text,
language='english',
removeStopwords = FALSE,
removeNumbers = TRUE,
stemWords = FALSE)
m_train
m_train <- create_matrix(train_split$Text,
language='english',
removeStopwords = FALSE,
removeNumbers = TRUE,
stemWords = FALSE)
matTrain <- as.matrix(m_train)
print(matTrain)
class(matTrain)
head(matTrain)
matTrain[1]
matTrain[2]
matTrain[0]
length(matTrain)
train_split <- VCorpus(VectorSource(my_data[index, ]$Text))
m_train <- create_matrix(train_split$Text,
language='english',
removeStopwords = FALSE,
removeNumbers = TRUE,
stemWords = FALSE)
m_train <- create_matrix(train_split,
language='english',
removeStopwords = FALSE,
removeNumbers = TRUE,
stemWords = FALSE)
index <- sample(1:nrow(my_data), size = .9 * nrow(my_data))
train_split <- VCorpus(VectorSource(my_data[index, ]$Text))
m_train <- create_matrix(train_split,
language='english',
removeStopwords = FALSE,
removeNumbers = TRUE,
stemWords = FALSE)
train_split
m_train <- DocumentTermMatrix(train_split)
matTrain <- as.matrix(m_train)
matTrain
m_train
write.table(m_train, 'test.txt')
write.table(matTrain, 'test.txt')
train_split <- VCorpus(VectorSource(my_data[index, ]$Text))
train_split <- VCorpus(VectorSource(my_data[-index, ]$Text))
m_test <- DocumentTermMatrix(test_split)
matTest <- as.matrix(m_test)
train_split <- VCorpus(VectorSource(my_data[index, ]$Text))
test_split <- VCorpus(VectorSource(my_data[-index, ]$Text))
m_train <- DocumentTermMatrix(train_split)
matTrain <- as.matrix(m_train)
#write.table(matTrain, 'test.txt')
m_test <- DocumentTermMatrix(test_split)
matTest <- as.matrix(m_test)
labelTrain <- as.factor(my_data[index, ]$Style)
labelTest <- as.factor(my_data[-index, ]$Style)
labelTest
model <- naiveBayes(matTrain, labelTrain)
pred <- predict(model, matTest)
install.packages(caret)
install.packages("caret")
install.packages(c("hardhat", "recipes", "caret"))
install.packages(c("rlang","hardhat", "recipes", "caret"))
install.packages(c("rlang", "hardhat", "recipes", "caret"))
library(caret)
my_data <- read_excel("../materiali/dataset.xlsx")
my_data <- data.frame(my_data)
index <- sample(1:nrow(my_data), size = .9 * nrow(my_data))
train_split <- VCorpus(VectorSource(my_data[index, ]$Text))
test_split <- VCorpus(VectorSource(my_data[-index, ]$Text))
m_train <- DocumentTermMatrix(train_split)
matTrain <- as.matrix(m_train)
#write.table(matTrain, 'test.txt')
m_test <- DocumentTermMatrix(test_split)
matTest <- as.matrix(m_test)
labelTrain <- as.factor(my_data[index, ]$Style)
labelTest <- as.factor(my_data[-index, ]$Style)
model <- naiveBayes(matTrain, labelTrain)
pred <- predict(model, matTest)
#importiamo le librerie che useremo in questa giornata
library(tidyverse)
library(ggplot2)
library(tokenizers)
library(wordcloud)
library(RColorBrewer)
library(SnowballC)
library(udpipe)
library(stopwords)
library(R.utils)
library(tm)
library(readxl)
library(RTextTools)
library(e1071)
library(caret)
#ricarichiamo il nostro file di testo
my_data <- read_excel("../materiali/dataset.xlsx")
my_data <- data.frame(my_data)
index <- sample(1:nrow(my_data), size = .9 * nrow(my_data))
train_split <- VCorpus(VectorSource(my_data[index, ]$Text))
test_split <- VCorpus(VectorSource(my_data[-index, ]$Text))
m_train <- DocumentTermMatrix(train_split)
matTrain <- as.matrix(m_train)
#write.table(matTrain, 'test.txt')
m_test <- DocumentTermMatrix(test_split)
matTest <- as.matrix(m_test)
labelTrain <- as.factor(my_data[index, ]$Style)
labelTest <- as.factor(my_data[-index, ]$Style)
model <- naiveBayes(matTrain, labelTrain)
pred <- predict(model, matTest)
confusionMatrix(labelTest, pred)
predict(model, c("Penso che Salvini sarebbe un ottimo premier"))
predict(model, c("Penso che Salvini sarebbe un pessimo premier"))
